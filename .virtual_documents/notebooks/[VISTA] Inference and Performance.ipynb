


# CLIP
from open_clip import create_model_from_pretrained, get_tokenizer

# Torch
import torch

# Metrics
from sklearn.metrics import confusion_matrix, roc_auc_score, precision_score, recall_score, f1_score, accuracy_score
from imblearn.metrics import specificity_score

# FS
import os
import io

# Others
from PIL import Image
import pandas as pd
import numpy as np
from typing import List, Dict


DATA_PATH = "../data/"
DESC_PATH = os.path.join(DATA_PATH, "data_description.csv")
IMG_PATH = os.path.join(DATA_PATH, "images")





template = 'This is a photo of '
context_length = 512
SIM_THRESHOLD = 0.6
PROB_THRESHOLD = 50

ABNORMAL_TYPES = ['normal', 'mtl_atrophy', 'wmh', 'other_atrophy']

DEMENTIA_TYPES = {
    0: "no_dementia",
    1: "other_dementia",
    2: "AD"
}

def get_labels(model, preprocess, tokenizer, images: List[str], labels: List[str], device:str, top_k: int = -1, is_bytes: bool = False) -> Dict:
  # Get embeddings of images and texts
  model.eval()
  if not is_bytes:
    img_embs = torch.stack([preprocess(Image.open(os.path.join(IMG_PATH, img))) for img in images]).to(device)
  else:
    img_embs = torch.stack([preprocess(Image.open(io.BytesIO(img))) for img in images]).to(device)

  print(f'Generated embeddings of {len(img_embs)} images.')
  text_embs = tokenizer([template + l for l in labels], context_length=context_length).to(device)
  print(f'Generated embeddings of {len(text_embs)} labels.')

  # Calculate similarity
  with torch.no_grad():
    image_features, text_features, logit_scale = model(img_embs, text_embs)

    logits = (logit_scale * image_features @ text_features.t()).detach().softmax(dim=-1)
    sorted_indices = torch.argsort(logits, dim=-1, descending=True)

    logits = logits.cpu().numpy()
    sorted_indices = sorted_indices.cpu().numpy()

  image_results = []
  for i, img in enumerate(images):
      pred = labels[sorted_indices[i][0]]
      top_k = len(labels) if top_k == -1 else top_k
      image_result = dict()
      for j in range(top_k):
          jth_index = sorted_indices[i][j]
          label = labels[jth_index].replace(template, "").replace(".", "").strip()
          score = logits[i][jth_index]
          image_result[label] = score
      image_results.append(image_result)

  return image_results

def replace_label(text: str, mapping_dict: dict):
    for key, value in mapping_dict.items():
        if key in text:
          text = text.replace(key, value)
    return text

def add_label_with_score(data: pd.DataFrame, result:dict, mapping_dict:dict):
  clone_data = data.copy()
  clone_data = clone_data.reset_index(drop=True)
  for idx, label in enumerate(result):
    threshold = min(max(label.values()), SIM_THRESHOLD)
    for lb_value, lb_score in label.items():
      lb_code = mapping_dict.get(lb_value, lb_value)
      clone_data.loc[idx, f'sim_score_{lb_code}'] = label[lb_value]

      clone_data.loc[idx, f'is_predicted_{lb_code}'] = 1 if label[lb_value] >= threshold else 0
  return clone_data

def is_correct_abnormality(row):
  for abnormality in row['abnormal_type'].split(","):
    if row[f'is_predicted_{abnormality}'] == 1:
      return 1
  return 0

def is_correct_dementia(row):
  true_dementia = row['label_text']
  return 1 if row[f'is_predicted_{true_dementia}'] == 1 else 0

def get_dementia_prob(row, dementia, diagnosis_prob:dict):
  dementia_prob = []
  for abnormal_type in ABNORMAL_TYPES:
    if row[f'is_predicted_{abnormal_type}'] == 1:
      dementia_prob.append(diagnosis_prob[f'is_{abnormal_type}'].get(dementia, 0))
  return max(dementia_prob) if len(dementia_prob) > 0 else 0

def add_predicted_dementia(data:pd.DataFrame, diagnosis_prob:dict, dementia_dict:dict):
  clone_data = data.copy()
  for dementia in dementia_dict.keys():
    clone_data[f'prob_{dementia_dict[dementia]}'] = clone_data.apply(lambda row: get_dementia_prob(row, dementia, diagnosis_prob), axis=1)
    clone_data[f'is_predicted_{dementia_dict[dementia]}'] = (clone_data[f'prob_{dementia_dict[dementia]}'] >= PROB_THRESHOLD).astype(int)
  return clone_data

def get_count_values(data: pd.DataFrame, column_name: str, is_ascending: bool = False):
  counts = data[column_name].value_counts(ascending=is_ascending)
  percentage = (data[column_name].value_counts(normalize=True, ascending=is_ascending) * 100).round(2)
  return pd.concat([counts, percentage], axis=1)

class EvalMetric:
  def __init__(self, labels:pd.Series, scores:pd.Series, predictions:pd.Series):
    self.labels = labels
    self.scores = scores
    # self.predictions = (scores >= threshold).astype(int)
    self.predictions = predictions

  def get_accuracy(self) -> float:
    return accuracy_score(self.labels, self.predictions)

  def get_precision(self) -> float:
    return precision_score(self.labels, self.predictions)

  def get_recall(self) -> float:
    # This metric is also sensitivity
    return recall_score(self.labels, self.predictions)

  def get_f1_score(self) -> float:
    return f1_score(self.labels, self.predictions)

  def get_specificity(self) -> float:
    return specificity_score(self.labels, self.predictions)

  def get_auc_score(self) -> float:
    return roc_auc_score(self.labels, self.scores)

  def get_overall_result(self) -> dict:
    return {
        'precision': self.get_precision(),
        'recall': self.get_recall(),
        'f1_score': self.get_f1_score(),
        'specificity': self.get_specificity(),
        'auc': self.get_auc_score(),
        'accuracy': self.get_accuracy()
    }

def get_evaluation(data, label_col:str, score_col_prefix:str, label_list:list) -> dict:
  result_dict = dict()
  clone_data = data.copy()
  for label_value in label_list:
    clone_data[f'is_{label_value}'] = clone_data[label_col].map(lambda val: label_value in val).astype(int)
    result_dict[label_value] = EvalMetric(labels=clone_data[f'is_{label_value}'], scores=clone_data[f'{score_col_prefix}_{label_value}'], predictions=clone_data[f'is_predicted_{label_value}']).get_overall_result()
  return result_dict





model, preprocess = create_model_from_pretrained('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')
tokenizer = get_tokenizer('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')
# model.load_state_dict(<path>)
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
print(f"Device: {device}")
model.to(device)





data = pd.read_csv(DESC_PATH)
data['label_text'] = data['label'].map(DEMENTIA_TYPES)
data.head(3)


# Get Dementia probability of each abnormality type 
DIAGNOSIS_PROB = dict()

for abnormal_type in ABNORMAL_TYPES:
  column_name = f'is_{abnormal_type}'
  data[column_name] = data['abnormal_type'].apply(lambda x: abnormal_type in x).astype(int)
  abnorm_to_dementia = get_count_values(data.groupby(column_name), 'label').reset_index()
  DIAGNOSIS_PROB[column_name] = abnorm_to_dementia[abnorm_to_dementia[column_name] == 1][['label', 'proportion']].set_index('label')['proportion'].T.to_dict()

DIAGNOSIS_PROB








column = 'abnormal_type'
mapping_dict = {
    'normal': 'brain on MRI, without signs of dementia',
    'mtl_atrophy': 'medial temporal lobe atrophy',
    'wmh': 'white matter hyperintensities',
    'other_atrophy': 'a type of brain atrophy',
}

template = "This is a photo of "

reversed_mapping_dict = {v:k for k, v in mapping_dict.items()}
labels = [template + label for label in reversed_mapping_dict.keys()]
labels





train_data, test_data = data.iloc[:120], data.iloc[120:]
train_images = train_data["img_path"].tolist()
test_images = test_data["img_path"].tolist()

train_image_labels = get_labels(model, preprocess, tokenizer, device=device, images=train_images, labels=labels, top_k=-1)
test_image_labels = get_labels(model, preprocess, tokenizer, device=device, images=test_images, labels=labels, top_k=-1)









train_data_with_result = add_label_with_score(data=train_data, result=train_image_labels, mapping_dict=reversed_mapping_dict)
train_data_with_result.head(3)





train_data_with_result['is_correct_abnormality'] = train_data_with_result.apply(lambda row: is_correct_abnormality(row), axis=1)
get_count_values(train_data_with_result, 'is_correct_abnormality')


baseline_result = get_evaluation(train_data_with_result, label_col='abnormal_type', score_col_prefix='sim_score', label_list=ABNORMAL_TYPES)
for abnormal_type in baseline_result.keys():
  print(abnormal_type)
  print(baseline_result[abnormal_type])
  print('----')








DIAGNOSIS_PROB


data_with_predicted_dementia = add_predicted_dementia(train_data_with_result, diagnosis_prob=DIAGNOSIS_PROB, dementia_dict=DEMENTIA_TYPES)
data_with_predicted_dementia.head(3)


data_with_predicted_dementia['is_dementia'] = (data_with_predicted_dementia['label'] != 0).astype(int)
data_with_predicted_dementia.head(3)


data_with_predicted_dementia['is_correct_dementia_type'] = data_with_predicted_dementia.apply(lambda row: is_correct_dementia(row), axis=1)
get_count_values(data_with_predicted_dementia, 'is_correct_dementia_type')


data_with_predicted_dementia['is_predicted_dementia'] = (data_with_predicted_dementia[[f'sim_score_{ab_type}' for ab_type in ABNORMAL_TYPES]].idxmax(axis=1).str.replace('sim_score_', '') != 'normal').astype(int)
data_with_predicted_dementia['max_sim_score'] = data_with_predicted_dementia[[f'sim_score_{ab_type}' for ab_type in ABNORMAL_TYPES]].max(axis=1)

# Reverse the score of normal to get the score on dementia
data_with_predicted_dementia['predicted_score'] = data_with_predicted_dementia.apply(lambda row: row['max_sim_score'] if row['is_predicted_dementia'] == 1 else 1 - row['max_sim_score'], axis=1)

prediction_result = EvalMetric(data_with_predicted_dementia['is_dementia'], 
                               data_with_predicted_dementia['predicted_score'], 
                               data_with_predicted_dementia['is_predicted_dementia']).get_overall_result()
prediction_result


dementia_result = get_evaluation(data_with_predicted_dementia, label_col='label_text', score_col_prefix='prob', label_list=DEMENTIA_TYPES.values())
for dementia_type in dementia_result.keys():
  print(dementia_type)
  print(dementia_result[dementia_type])
  print('----')











test_data_with_result = add_label_with_score(data=test_data, result=test_image_labels, mapping_dict=reversed_mapping_dict)
test_data_with_result.head(3)





test_data_with_result['is_correct_abnormality'] = test_data_with_result.apply(lambda row: is_correct_abnormality(row), axis=1)
get_count_values(test_data_with_result, 'is_correct_abnormality')


baseline_result = get_evaluation(test_data_with_result, label_col='abnormal_type', score_col_prefix='sim_score', label_list=ABNORMAL_TYPES)
for abnormal_type in baseline_result.keys():
  print(abnormal_type)
  print(baseline_result[abnormal_type])
  print('----')








data_with_predicted_dementia = add_predicted_dementia(test_data_with_result, diagnosis_prob=DIAGNOSIS_PROB, dementia_dict=DEMENTIA_TYPES)
data_with_predicted_dementia.head(3)


data_with_predicted_dementia['is_dementia'] = (data_with_predicted_dementia['label'] != 0).astype(int)
data_with_predicted_dementia.head(3)


data_with_predicted_dementia['is_correct_dementia_type'] = data_with_predicted_dementia.apply(lambda row: is_correct_dementia(row), axis=1)
get_count_values(data_with_predicted_dementia, 'is_correct_dementia_type')


data_with_predicted_dementia['is_predicted_dementia'] = (data_with_predicted_dementia[[f'sim_score_{ab_type}' for ab_type in ABNORMAL_TYPES]].idxmax(axis=1).str.replace('sim_score_', '') != 'normal').astype(int)
data_with_predicted_dementia['max_sim_score'] = data_with_predicted_dementia[[f'sim_score_{ab_type}' for ab_type in ABNORMAL_TYPES]].max(axis=1)

# Reverse the score of normal to get the score on dementia
data_with_predicted_dementia['predicted_score'] = data_with_predicted_dementia.apply(lambda row: row['max_sim_score'] if row['is_predicted_dementia'] == 1 else 1 - row['max_sim_score'], axis=1)

prediction_result = EvalMetric(data_with_predicted_dementia['is_dementia'], 
                               data_with_predicted_dementia['predicted_score'], 
                               data_with_predicted_dementia['is_predicted_dementia']).get_overall_result()
prediction_result


dementia_result = get_evaluation(data_with_predicted_dementia, label_col='label_text', score_col_prefix='prob', label_list=DEMENTIA_TYPES.values())
for dementia_type in dementia_result.keys():
  print(dementia_type)
  print(dementia_result[dementia_type])
  print('----')








PUBLIC_DATASET_PATH = os.path.join(DATA_PATH, "public_HF_dataset")
public_test = pd.read_parquet(os.path.join(PUBLIC_DATASET_PATH, 'test.parquet'))
public_test.shape


public_images = [data["bytes"] for data in public_test["image"].tolist()]
public_test_result = get_labels(model=model, preprocess=preprocess, tokenizer=tokenizer, device=device, images=public_images, labels=labels, is_bytes=True)
len(public_test_result)


test_public_with_result = add_label_with_score(public_test, result=public_test_result, mapping_dict=reversed_mapping_dict)
test_public_with_result.head(3)


test_public_with_result['is_dementia'] = (test_public_with_result['label'] != 2).astype(int)
test_public_with_result['is_predicted_dementia'] = (test_public_with_result[[f'sim_score_{abnormality}' for abnormality in ABNORMAL_TYPES]].idxmax(axis=1).str.replace("sim_score_", "") != 'normal').astype(int)
test_public_with_result['sim_score'] = test_public_with_result[[f'sim_score_{abnormality}' for abnormality in ABNORMAL_TYPES]].max(axis=1)
test_public_with_result['predicted_score'] = test_public_with_result.apply(lambda row: row['sim_score'] if row['is_predicted_dementia'] == 1 else 1 - row['sim_score'], axis=1)
test_public_with_result.head(3)


test_public_with_result['is_correct'] = (test_public_with_result['is_dementia'] == test_public_with_result['is_predicted_dementia']).astype(int)
get_count_values(test_public_with_result, 'is_correct')


public_result = EvalMetric(test_public_with_result['is_dementia'], test_public_with_result['predicted_score'], test_public_with_result['is_predicted_dementia']).get_overall_result()
public_result



